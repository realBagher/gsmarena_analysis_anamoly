{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip = 'http://185.162.230.48:80'\n",
    "\n",
    "\n",
    "# def get_proxies(ip):    \n",
    "#     url = 'https://free-proxy-list.net/anonymous-proxy.html'\n",
    "#     headers = {\"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "#     time.sleep(5)\n",
    "#     response = requests.get(url, headers=headers, proxies={'http': ip})\n",
    "#     content = BeautifulSoup(response.content, 'html.parser')\n",
    "#     rows = content.find('table').find_all('tr')\n",
    "#     rows = rows[1:]\n",
    "#     proxies = []\n",
    "#     for row in rows:\n",
    "#         tds = row.find_all('td')\n",
    "#         if tds[-2].text == 'no':\n",
    "#             proxy = f'http://{tds[0].text}:{tds[1].text}'\n",
    "#         if tds[-2].text == 'yes':\n",
    "#             proxy = f'https://{tds[0].text}:{tds[1].text}'\n",
    "#         proxies.append(proxy)\n",
    "#     return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proxies.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    ips = list(csv_reader)\n",
    "\n",
    "ip_addresses = [ip[0] for ip in ips]\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "def proxy_request(url, ip_addresses):\n",
    "    while True:\n",
    "        try:\n",
    "            ua = UserAgent()    \n",
    "            headers = {\"Accept-Language\": \"en-US,en;q=0.5\", 'User-Agent': ua.random}\n",
    "            proxy = random.randint(0, len(ip_addresses) - 1)\n",
    "            proxies = {\"http\": ip_addresses[proxy]}\n",
    "            response = session.get(url, proxies=proxies, timeout=5, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                break\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Rate limit exceeded. Waiting before retrying...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"Request failed with status code: {response.status_code}\")\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.gsmarena.com/makers.php3'\n",
    "response = proxy_request(url, ip_addresses)\n",
    "content = BeautifulSoup(response.content.decode('utf-8'), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://www.gsmarena.com/makers.php3/'\n",
    "maker_urls = dict()\n",
    "query = list(map(lambda x: x.find('a'), content.find('table').find_all('td')))\n",
    "maker_urls = dict(zip(list(map(lambda x: x.text.split()[0], query)), list(map(lambda x: prefix + x.attrs['href'], query))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maker_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maker_urls['Acer100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list = [\n",
    "    'Samsung1382',\n",
    "    'Apple118',\n",
    "    'Xiaomi377',\n",
    "    'Huawei441',\n",
    "    'alcatel409',\n",
    "    'Sony',\n",
    "    'Sony158',\n",
    "    'LG667',\n",
    "    'Lenovo246',\n",
    "    'ZTE369',\n",
    "    'Nokia576',\n",
    "    'BLU369',\n",
    "    'Infinix125',\n",
    "    'HTC287',\n",
    "    'Asus203',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://www.gsmarena.com/'\n",
    "maker_brands = dict()\n",
    "\n",
    "for maker in maker_urls:\n",
    "    if maker in brand_list:\n",
    "        maker_brands[maker] = {}  # Initialize the dictionary for the maker\n",
    "        next_url = maker_urls[maker]  # Start with the first page URL\n",
    "        while next_url:\n",
    "            time.sleep(3)  # Respectful crawling by waiting\n",
    "            response = proxy_request(next_url, ip_addresses)  # Assuming proxy_request function handles the request\n",
    "            content = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Process the current page\n",
    "            query = content.find('div', {'class': 'makers'}).find_all('a')\n",
    "            maker_brands[maker].update(dict(map(lambda x: (x.text, prefix + x.attrs['href']), query)))\n",
    "            \n",
    "            # Check for the next page\n",
    "            next_page = content.find('div', {'class': 'nav-pages'}).find('a', {'title': 'Next page'})\n",
    "            if next_page:\n",
    "                next_url = prefix + next_page.attrs['href']  # Update the URL for the next request\n",
    "            else:\n",
    "                next_url = None  # No more pages, end the loop\n",
    "            \n",
    "            print(maker, \"Page processed\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maker_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = 'urls.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(maker_urls, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict_with_headers = {}\n",
    "\n",
    "for brand in maker_brands:\n",
    "    if brand in brand_list:\n",
    "        info_dict_with_headers[brand] = {}\n",
    "        for device in maker_brands[brand]:\n",
    "            print(device)\n",
    "            url = maker_brands[brand][device]\n",
    "            # url = url.replace('https://www.gsmarena.com/makers.php3', 'https://www.gsmarena.com/makers.php3/')\n",
    "            time.sleep(3)\n",
    "            response = proxy_request(url, ip_addresses)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table_list = soup.find_all('table')\n",
    "            info_dict_with_headers[brand][device] = {}\n",
    "\n",
    "            for table in table_list:\n",
    "                # Attempt to find the table header\n",
    "                header = table.find('th')\n",
    "                if header:\n",
    "                    header_text = header.get_text(strip=True)\n",
    "                else:\n",
    "                    # If no <th> is found, or there is a need to identify the header differently, adjust here\n",
    "                    header_text = \"Unknown\"  # Placeholder if no header is found or defined differently\n",
    "\n",
    "                # Initialize the dictionary for this header if not already present\n",
    "                if header_text not in info_dict_with_headers:\n",
    "                    info_dict_with_headers[brand][device][header_text] = []\n",
    "\n",
    "                last_key = None  # Keep track of the last non-empty key for rows without a 'ttl'\n",
    "\n",
    "                # Iterate through each row in the table\n",
    "                for row in table.find_all('tr'):\n",
    "                    ttl_element = row.find(\"td\", class_=\"ttl\")\n",
    "                    nfo_element = row.find(\"td\", class_=\"nfo\")\n",
    "\n",
    "                    if ttl_element and ttl_element.get_text(strip=True):\n",
    "                        # If ttl_element has text, update last_key\n",
    "                        key = ttl_element.get_text(strip=True)\n",
    "                        last_key = key\n",
    "                    else:\n",
    "                        # If ttl_element is empty, use the last_key\n",
    "                        key = last_key\n",
    "\n",
    "                    if nfo_element:\n",
    "                        value = nfo_element.get_text(strip=True)\n",
    "                        # Append the key-value pair under the current header\n",
    "                        if key:\n",
    "                            info_dict_with_headers[brand][device][header_text].append({key: value})\n",
    "                        else:\n",
    "                            # Handle case where there's a value without a key (could append to last key's value or handle as needed)\n",
    "                            pass\n",
    "\n",
    "            print(f'{device} Done!')\n",
    "        print(f'{brand} Done!')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'complete_required_data.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(info_dict_with_headers, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict_with_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://www.gsmarena.com/'\n",
    "maker_brands = dict()\n",
    "\n",
    "for maker in maker_urls:\n",
    "    if maker not in brand_list:\n",
    "        maker_brands[maker] = {}  # Initialize the dictionary for the maker\n",
    "        next_url = maker_urls[maker]  # Start with the first page URL\n",
    "        while next_url:\n",
    "            time.sleep(3)  # Respectful crawling by waiting\n",
    "            response = proxy_request(next_url, ip_addresses)  # Assuming proxy_request function handles the request\n",
    "            content = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Process the current page\n",
    "            query = content.find('div', {'class': 'makers'}).find_all('a')\n",
    "            maker_brands[maker].update(dict(map(lambda x: (x.text, prefix + x.attrs['href']), query)))\n",
    "            \n",
    "            # Check for the next page\n",
    "            next_page = content.find('div', {'class': 'nav-pages'}).find('a', {'title': 'Next page'})\n",
    "            if next_page:\n",
    "                next_url = prefix + next_page.attrs['href']  # Update the URL for the next request\n",
    "            else:\n",
    "                next_url = None  # No more pages, end the loop\n",
    "            \n",
    "            print(maker, \"Page processed\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict_with_headers = {}\n",
    "\n",
    "for brand in maker_urls:\n",
    "    if brand not in brand_list:\n",
    "        info_dict_with_headers[brand] = {}\n",
    "        for device in maker_urls[brand]:\n",
    "            print(device)\n",
    "            url = maker_urls[brand][device]\n",
    "            url = url.replace('https://www.gsmarena.com/makers.php3', 'https://www.gsmarena.com/makers.php3/')\n",
    "            time.sleep(3)\n",
    "            response = proxy_request(url, ip_addresses)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table_list = soup.find_all('table')\n",
    "            info_dict_with_headers[brand][device] = {}\n",
    "\n",
    "            for table in table_list:\n",
    "                # Attempt to find the table header\n",
    "                header = table.find('th')\n",
    "                if header:\n",
    "                    header_text = header.get_text(strip=True)\n",
    "                else:\n",
    "                    # If no <th> is found, or there is a need to identify the header differently, adjust here\n",
    "                    header_text = \"Unknown\"  # Placeholder if no header is found or defined differently\n",
    "\n",
    "                # Initialize the dictionary for this header if not already present\n",
    "                if header_text not in info_dict_with_headers:\n",
    "                    info_dict_with_headers[brand][device][header_text] = []\n",
    "\n",
    "                last_key = None  # Keep track of the last non-empty key for rows without a 'ttl'\n",
    "\n",
    "                # Iterate through each row in the table\n",
    "                for row in table.find_all('tr'):\n",
    "                    ttl_element = row.find(\"td\", class_=\"ttl\")\n",
    "                    nfo_element = row.find(\"td\", class_=\"nfo\")\n",
    "\n",
    "                    if ttl_element and ttl_element.get_text(strip=True):\n",
    "                        # If ttl_element has text, update last_key\n",
    "                        key = ttl_element.get_text(strip=True)\n",
    "                        last_key = key\n",
    "                    else:\n",
    "                        # If ttl_element is empty, use the last_key\n",
    "                        key = last_key\n",
    "\n",
    "                    if nfo_element:\n",
    "                        value = nfo_element.get_text(strip=True)\n",
    "                        # Append the key-value pair under the current header\n",
    "                        if key:\n",
    "                            info_dict_with_headers[brand][device][header_text].append({key: value})\n",
    "                        else:\n",
    "                            # Handle case where there's a value without a key (could append to last key's value or handle as needed)\n",
    "                            pass\n",
    "\n",
    "            print(f'{device} Done!')\n",
    "        print(f'{brand} Done!')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'complete_data.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(info_dict_with_headers, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
